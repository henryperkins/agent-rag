# =============================================================================
# AGENTIC RAG - ENVIRONMENT CONFIGURATION TEMPLATE
# =============================================================================
# Copy this file to .env and fill in your actual values
# Documentation: See README.md for detailed configuration guide
# =============================================================================

# -----------------------------------------------------------------------------
# APPLICATION SETTINGS
# -----------------------------------------------------------------------------
PROJECT_NAME=agentic-azure-chat
NODE_ENV=development
PORT=8787

# -----------------------------------------------------------------------------
# AZURE AI SEARCH CONFIGURATION
# -----------------------------------------------------------------------------
# Your Azure AI Search service endpoint and credentials
# Requires: Hybrid semantic search enabled on your index
AZURE_SEARCH_ENDPOINT=https://your-search-service.search.windows.net

# Management API version (for index operations, default works for most use cases)
AZURE_SEARCH_API_VERSION=2025-08-01-preview

# Data Plane API version (for search queries)
# ‚ö†Ô∏è  IMPORTANT: Use valid stable version to avoid errors
# Valid versions: 2025-09-01 (stable, recommended), 2025-08-01-preview
# See docs/TROUBLESHOOTING.md for version validation
AZURE_SEARCH_DATA_PLANE_API_VERSION=2025-09-01

AZURE_SEARCH_INDEX_NAME=your-index-name
AZURE_SEARCH_API_KEY=your-search-api-key

# Optional: Knowledge Agent Name (if using Azure AI Search knowledge agents)
AZURE_KNOWLEDGE_AGENT_NAME=your-knowledge-agent
RETRIEVAL_STRATEGY=direct
KNOWLEDGE_AGENT_INCLUDE_ACTIVITY=true
KNOWLEDGE_AGENT_INCLUDE_REFERENCES=true
KNOWLEDGE_AGENT_INCLUDE_SOURCE_DATA=true
KNOWLEDGE_AGENT_ATTEMPT_FAST_PATH=false
KNOWLEDGE_AGENT_TOP_K=5

# -----------------------------------------------------------------------------
# AZURE OPENAI CONFIGURATION
# -----------------------------------------------------------------------------
# ‚ö†Ô∏è  IMPORTANT: Use DEPLOYMENT NAMES, not model names
# Example: If your deployment is named "gpt-5", use "gpt-5"
# To list deployments: az cognitiveservices account deployment list --name <resource> --resource-group <rg>

# Main GPT deployment for answer generation
AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com
AZURE_OPENAI_API_VERSION=v1
AZURE_OPENAI_GPT_DEPLOYMENT=gpt-5  # Your deployment name in Azure OpenAI Studio
AZURE_OPENAI_GPT_MODEL_NAME=gpt-5  # Model name (for reference only)
AZURE_OPENAI_API_KEY=your-openai-api-key

# Embedding deployment for vector similarity
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-large  # Your embedding deployment name
AZURE_OPENAI_EMBEDDING_ENDPOINT=https://your-embedding.cognitiveservices.azure.com
AZURE_OPENAI_EMBEDDING_API_KEY=your-embedding-api-key

# -----------------------------------------------------------------------------
# GOOGLE CUSTOM SEARCH (Optional - for web search)
# -----------------------------------------------------------------------------
# Leave blank to disable web search functionality
GOOGLE_SEARCH_API_KEY=your-google-api-key
GOOGLE_SEARCH_ENGINE_ID=your-search-engine-id
GOOGLE_SEARCH_ENDPOINT=https://customsearch.googleapis.com/customsearch/v1

# -----------------------------------------------------------------------------
# AZURE AGENT SERVICE (Optional - for MCP tools)
# -----------------------------------------------------------------------------
# Required for Azure AI Foundry MCP server agent operations
# See docs/AZURE_FOUNDRY_MCP_TEST_REPORT.md for validation details
# See docs/AZURE_AGENT_SERVICE_SETUP.md for credential configuration guide

# Default agent ID for query operations
# To find agent IDs: az ml workspace list OR use MCP list_agents tool
DEFAULT_AGENT_ID=your-agent-id

# Optional: Service Principal credentials for agent service
# Only needed if not using Azure CLI (az login) or Managed Identity
# AZURE_CLIENT_ID=your-client-id
# AZURE_TENANT_ID=your-tenant-id
# AZURE_CLIENT_SECRET=your-client-secret

# -----------------------------------------------------------------------------
# RETRIEVAL SETTINGS
# -----------------------------------------------------------------------------
RAG_TOP_K=5
RERANKER_THRESHOLD=2.5
RETRIEVAL_FALLBACK_RERANKER_THRESHOLD=1.5
MAX_DOCS_FOR_RERANKER=100
TARGET_INDEX_MAX_DOCUMENTS=100
RETRIEVAL_MIN_DOCS=3

# ADAPTIVE RETRIEVAL (Query Reformulation with Quality Assessment)
# Cost Impact: +$5-15/month (coverage assessment + reformulation LLM calls) | Risk: LOW
# Benefit: 30-50% reduction in "I do not know" responses
# Automatically reformulates queries when retrieval quality is insufficient
ENABLE_ADAPTIVE_RETRIEVAL=false
ADAPTIVE_MIN_COVERAGE=0.4          # Minimum query coverage threshold (0.0-1.0)
ADAPTIVE_MIN_DIVERSITY=0.3         # Minimum result diversity threshold (0.0-1.0)
  ADAPTIVE_MAX_ATTEMPTS=3            # Maximum reformulation attempts

  # SEARCH COVERAGE GATE (Azure @search.coverage)
  # If coverage (fraction of index partitions searched) falls below this
  # threshold, the system will emit a 'low_coverage' activity note and may
  # trigger a more conservative fallback path.
  SEARCH_MIN_COVERAGE=0.8

# -----------------------------------------------------------------------------
# CRITIC SETTINGS (Quality Assurance)
# -----------------------------------------------------------------------------
ENABLE_CRITIC=true
CRITIC_MAX_RETRIES=1
CRITIC_THRESHOLD=0.8

# CITATION TRACKING (Learning Loop for Retrieval)
# Cost Impact: Minimal | Risk: LOW | Requires: ENABLE_SEMANTIC_MEMORY=true
ENABLE_CITATION_TRACKING=true

# WEB QUALITY FILTERING (Spam & Low-Quality Result Removal)
# Cost Impact: +$10-20/month (embedding calls) | Risk: LOW
ENABLE_WEB_QUALITY_FILTER=true
WEB_MIN_AUTHORITY=0.3
WEB_MAX_REDUNDANCY=0.9
WEB_MIN_RELEVANCE=0.3

# ACADEMIC SEARCH (Semantic Scholar + arXiv Integration)
# Cost Impact: Free API calls | Risk: LOW | Benefit: Access to 200M+ papers
ENABLE_ACADEMIC_SEARCH=true
ACADEMIC_SEARCH_MAX_RESULTS=6

# ADAPTIVE RETRIEVAL (Query Reformulation for Failed Searches)
# Cost Impact: +10-15% tokens (retry LLM calls) | Risk: LOW | Benefit: -30-50% "I don't know" responses
# üí° RECOMMENDED: Enable this to reduce failed queries
ENABLE_ADAPTIVE_RETRIEVAL=true
ADAPTIVE_MIN_COVERAGE=0.4
ADAPTIVE_MIN_DIVERSITY=0.3
ADAPTIVE_MAX_ATTEMPTS=3
SEARCH_MIN_COVERAGE=0.8

# CRAG (Corrective RAG - Self-Grading Retrieval)
# Cost Impact: +5-10% tokens (evaluation LLM calls) | Risk: LOW | Benefit: -30-50% hallucination
# üí° RECOMMENDED: Enable this for higher accuracy
ENABLE_CRAG=true
CRAG_RELEVANCE_THRESHOLD=0.5
CRAG_MIN_CONFIDENCE_FOR_USE=ambiguous  # Options: correct | ambiguous | incorrect

# -----------------------------------------------------------------------------
# CONTEXT ENGINEERING (GPT-5: 272K input capacity)
# -----------------------------------------------------------------------------
CONTEXT_HISTORY_TOKEN_CAP=40000  # Increased from 1800 for full conversation history
CONTEXT_SUMMARY_TOKEN_CAP=10000  # Increased from 600 for richer summaries
CONTEXT_SALIENCE_TOKEN_CAP=5000  # Increased from 400 for more salient points
CONTEXT_MAX_RECENT_TURNS=50  # Increased from 12 for longer conversations
CONTEXT_MAX_SUMMARY_ITEMS=20  # Increased from 6 for better coverage
CONTEXT_MAX_SALIENCE_ITEMS=15  # Increased from 6 for more context
PLANNER_CONFIDENCE_DUAL_RETRIEVAL=0.45

# -----------------------------------------------------------------------------
# WEB SEARCH SETTINGS (GPT-5: 272K input capacity)
# -----------------------------------------------------------------------------
WEB_CONTEXT_MAX_TOKENS=30000  # Increased from 8000 for comprehensive web content
WEB_RESULTS_MAX=15  # Increased from 6 for more sources
WEB_SEARCH_MODE=full

# Web search safety and recency controls
WEB_SAFE_MODE=off  # Options: off | active | high (Google SafeSearch)
WEB_DEFAULT_RECENCY=  # Date restriction (e.g., d7 for last 7 days, m1 for last month, leave empty for no restriction)
WEB_EMBEDDING_BATCH_SIZE=16  # Batch size for web quality filter embeddings

# -----------------------------------------------------------------------------
# SECURITY & RATE LIMITING
# -----------------------------------------------------------------------------
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=10
REQUEST_TIMEOUT_MS=30000
CORS_ORIGIN=http://localhost:5173,http://localhost:5174,http://localhost:5175
LOG_LEVEL=info

# =============================================================================
# FEATURE FLAGS - ADVANCED CAPABILITIES
# =============================================================================
# ‚ö†Ô∏è  All advanced features are DISABLED by default for safety
# üí° Enable progressively based on your needs and budget
# =============================================================================

# LAZY RETRIEVAL (Summary-First Document Loading)
# Cost Impact: -40-50% retrieval token savings | Risk: LOW
# üí° RECOMMENDED: Enabled by default for cost savings
ENABLE_LAZY_RETRIEVAL=true
LAZY_SUMMARY_MAX_CHARS=1000  # Increased from 300 for more informative summaries
LAZY_PREFETCH_COUNT=20  # Increased from 10 to pre-fetch more documents
LAZY_LOAD_THRESHOLD=0.5

# SEMANTIC SUMMARY SELECTION (Embedding-Based Context)
# Cost Impact: +$20-30/month | Risk: LOW
ENABLE_SEMANTIC_SUMMARY=false

# INTENT ROUTING (Adaptive Model Selection)
# Cost Impact: -20-30% savings | Risk: LOW
# üí° RECOMMENDED: Enabled by default for cost savings
ENABLE_INTENT_ROUTING=true

# ‚ö†Ô∏è  CRITICAL: INTENT_CLASSIFIER_MODEL must be a DEPLOYMENT NAME (not model name)
# Example: Use "gpt-5" if that's your deployment name
# See docs/TROUBLESHOOTING.md for DeploymentNotFound errors
INTENT_CLASSIFIER_MODEL=gpt-5  # Replace with your actual deployment name

# ‚ö†Ô∏è  CRITICAL: Must be >= 16 (Azure OpenAI minimum)
INTENT_CLASSIFIER_MAX_TOKENS=500  # Increased from 100 for better intent analysis

# Model routing (can be model names OR deployment names)
MODEL_FAQ=gpt-5
MODEL_FACTUAL=gpt-5
MODEL_RESEARCH=gpt-5
MODEL_CONVERSATIONAL=gpt-5

# Token limits per intent (GPT-5: 128K output capacity)
MAX_TOKENS_FAQ=2000  # Increased from 500 for detailed FAQ answers
MAX_TOKENS_FACTUAL=3000  # Increased from 600 for thorough factual responses
MAX_TOKENS_RESEARCH=16000  # Increased from 2000 for comprehensive research
MAX_TOKENS_CONVERSATIONAL=1500  # Increased from 400 for natural conversations

# SEMANTIC MEMORY (Persistent Cross-Session Context)
# Cost Impact: +$50-100/month | Risk: LOW (requires better-sqlite3)
ENABLE_SEMANTIC_MEMORY=false
SEMANTIC_MEMORY_DB_PATH=./data/semantic-memory.db
SEMANTIC_MEMORY_RECALL_K=3
SEMANTIC_MEMORY_MIN_SIMILARITY=0.6
SEMANTIC_MEMORY_PRUNE_AGE_DAYS=90

# QUERY DECOMPOSITION (Complex Multi-Step Questions)
# Cost Impact: +2-3x tokens for complex queries | Risk: MEDIUM
ENABLE_QUERY_DECOMPOSITION=false
DECOMPOSITION_COMPLEXITY_THRESHOLD=0.6
DECOMPOSITION_MAX_SUBQUERIES=8

# WEB SEARCH RERANKING (Unified Azure + Web Results)
# Cost Impact: Minimal | Risk: LOW
ENABLE_WEB_RERANKING=false
RRF_K_CONSTANT=60
RERANKING_TOP_K=10
ENABLE_SEMANTIC_BOOST=false
SEMANTIC_BOOST_WEIGHT=0.3

# =============================================================================
# RECOMMENDED CONFIGURATIONS
# =============================================================================

# MINIMAL (Development/Budget) - Est. $200-300/month
# ENABLE_CRITIC=true
# ENABLE_INTENT_ROUTING=true
# ENABLE_LAZY_RETRIEVAL=true

# BALANCED (Production) - Est. $400-600/month
# ENABLE_CRITIC=true
# ENABLE_INTENT_ROUTING=true
# ENABLE_LAZY_RETRIEVAL=true
# ENABLE_WEB_RERANKING=true
# ENABLE_SEMANTIC_SUMMARY=true

# FULL FEATURES (Enterprise) - Est. $700-1000/month
# All flags enabled

# =============================================================================
# PROGRESSIVE ENABLEMENT (Week-by-Week)
# =============================================================================
# Week 1: Enable INTENT_ROUTING + LAZY_RETRIEVAL (cost optimization)
# Week 2: Add WEB_RERANKING + SEMANTIC_SUMMARY (quality boost)
# Week 3: Add QUERY_DECOMPOSITION + SEMANTIC_MEMORY (advanced features)
# =============================================================================
