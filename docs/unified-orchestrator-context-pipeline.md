# Unified Orchestrator & Context Pipeline Design

## Background & Goals
- `/chat` and `/chat/stream` both delegate to the unified orchestrator via `handleEnhancedChat` and `handleChatStream`. Streaming requests now flow through `runSession` with identical planning, retrieval, critique loops, and telemetry hooks, with `createSessionRecorder` cloning every orchestrator event into telemetry while forwarding them to the SSE caller.
- All turn history is forwarded verbatim into retrieval (`backend/src/azure/agenticRetrieval.ts:41`) resulting in uncontrollable context growth, duplicated evidence, and token waste.
- Planner outcomes (`backend/src/orchestrator/plan.ts:34`) previously relied on legacy services; the orchestrator now enforces these decisions with actual tool dispatch but still needs continued evaluation.
- Production-quality agentic RAG requires a single orchestrator responsible for planning, context budgeting, multimodal retrieval, synthesis, critique, and telemetry.

**Goals**
1. Provide a unified orchestration service that powers both synchronous and streaming experiences without duplicating logic.
2. Establish a context pipeline that summarizes history, persists salient memory, and selects the minimal window for each tool call.
3. Enforce planner decisions with tool routing, retrieval fallback ordering, and consistent critic/evaluator loops.
4. Capture structured telemetry (prompts, token budgets, tool usage) for observability and evaluation.

**Non-Goals**
- Replacing Azure AI Search Knowledge Agent or vector fallback integrations.
- Introducing new UI surfaces beyond the telemetry required to visualize pipeline stages.

## Proposed Architecture

### Unified Orchestrator Module
- Maintain `backend/src/orchestrator/index.ts` that exposes `runSession(options)` returning a rich session trace:
  - Inputs: full `AgentMessage[]`, execution mode (`sync` | `stream`), session id, feature flags.
  - Outputs: final answer, citations, activity timeline, emitted events, telemetry bundle.
- Responsibilities:
  1. **Planning** – Invoke `getPlan` once per turn with preprocessed history (see Context Pipeline) and augment response with guardrails (confidence thresholds, fallback heuristics).
  2. **Tool Dispatch** – Route to `agenticRetrieveTool`, `webSearchTool`, or a combined branch. Planner fallbacks must surface rationale when overridden.
  3. **Synthesis** – Call `answerTool` with structured context generated by the context pipeline and attach source metadata.
  4. **Critique Loop** – Run `enhancedCritiqueDraft` (and future evaluators) with retry policies from `withRetry` (`backend/src/utils/resilience.ts:20`).
  5. **Telemetry** – Emit step-level events (start/finish, tokens in/out, cost estimates) appended to a structured trace.
- Existing services (`handleEnhancedChat`, `handleChatStream`) already delegate to the orchestrator; future updates should extend this flow rather than rebuilding parallel pipelines.
- Provide dependency injection for tools and telemetry sinks to make local testing easier (mock retrieval, stub critics).

### Context Pipeline
- **Sanitized History View** – Start from `sanitizeInput` output (`backend/src/middleware/sanitize.ts:6`). Apply a configurable turn limit (e.g., 12 most recent user/assistant messages) and strip redundant assistant echoes.
- **Rolling Summary** – Introduce `conversationSummarizer` module that compacts older turns once the token estimate exceeds threshold T. Persist summary entries in a scratchpad store (in-memory map initially, later external KV).
- **Salience Store** – Capture key facts, user preferences, and unresolved questions using prompt-based extraction after each assistant reply. Store as structured records with metadata (topic, lastSeen turn, decay score).
- **Selection/Compression** – Before calling retrieval or planner, assemble context by:
  1. Latest N raw turns.
  2. Most relevant summary snippets (semantic similarity against current user turn).
  3. Top-K salience notes filtered by freshness.
- **Token Budgeting** – Implement a `ContextBudget` helper that tracks estimated tokens using model-specific tokenizers and trims inputs to stay within configurable ceilings (e.g., 3k for planner, 6k for retrieval). Expose metrics in telemetry.

### Execution Flow
1. **Input Receipt** – `/chat` and `/chat/stream` both call `runSession` with the sanitized message list and a generated session id.
2. **Context Preparation** – Orchestrator builds context snapshot (raw turns + summaries + salience) via Context Pipeline, capturing summary-selection statistics so downstream tooling and telemetry can reason about which bullets were retained or discarded.
3. **Planning** – `getPlan` executes on compacted history. If confidence < threshold, orchestrator may escalate to dual retrieval (knowledge + web) and annotate reason.
4. **Retrieval** – Execute primary tool path with `withRetry`. On failure, fall back to secondary (vector search, web search) while logging decision metadata.
5. **Synthesis & Critique** – `answerTool` consumes curated context; critic loop runs until acceptance or retry limit. Results appended to trace.
6. **Event Emission** – `createSessionRecorder` subscribes to orchestrator events, persisting sanitized telemetry and mirroring each event to the streaming handler so SSE clients receive the same plan/retrieval/token/critique updates. Sync mode aggregates and returns the final payload + trace.
7. **Telemetry Persist** – At completion, orchestrator writes trace to telemetry sink (initially in-memory with `/admin/telemetry`, later pluggable).

### Data & API Changes
- **Session Trace Schema** – Define new type in `shared/types.ts` (e.g., `SessionTrace`) capturing steps, messages, tool calls, token usage, errors.
- **Route Responses** – `/chat` responses include `traceId`, `plan`, `contextBudget`, `summarySelection`, and `criticSummary` inside `metadata`. SSE stream emits `plan`, `context`, `tool`, and `telemetry` updates, with the telemetry payload embedding `summary_selection` stats for richer UX.
- **Session Identity** – Session ids are either supplied by the client or derived from a stable fingerprint (first non-system turns + client fingerprint) so memory, salience, and telemetry stores remain consistent across turns without leaking between users.
- **Configuration** – Add context budget limits, summary thresholds, and telemetry sinks to `config/app.ts` with sane defaults.

## Implementation Plan

### Phase 1 – Orchestrator Skeleton (1 sprint)
1. Create orchestrator module with interfaces and integrate into `/chat` while preserving current outputs.
2. Update `/chat/stream` to consume orchestrator events, falling back to aggregated output until full streaming support is ready.
3. Add unit tests for orchestrator decision flow using mocked tools.

### Phase 2 – Context Pipeline MVP (1–2 sprints)
1. Implement rolling summaries and salience store with in-memory persistence.
2. Introduce context budgeting helper and integrate into planner/retrieval calls.
3. Expand telemetry to record context components and token costs; expose via `/admin/telemetry`.

### Phase 3 – Tool Routing & Critique Enforcement (1 sprint)
1. Wire planner actions to actual tool invocations (enable Bing web search path, combined retrieval).
2. Ensure critic loop runs for both sync and streaming flows with consistent metadata.
3. Update frontend to display new events (planning status, context snapshots, critique summary).

### Phase 4 – Hardening (ongoing)
1. Add integration tests covering orchestration permutations (answer, retrieve, web search, fallback vector).
2. Stress-test context budgets with long conversations; refine summary heuristics.
3. Evaluate telemetry storage options (OpenTelemetry exporter, durable store).

## Open Questions
- What persistence layer do we adopt for summaries/salience (Redis, Azure Table) once in-memory proves insufficient?
- How do we redact sensitive user data inside stored traces without losing debugging fidelity?
- Should planner confidence thresholds be static or dynamically tuned based on evaluation feedback?
